{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "\n",
    "class GridWorld(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"console\"], \"render_fps\": 30}\n",
    "\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    UP = 2\n",
    "    DOWN = 3\n",
    "\n",
    "    def __init__(self, grid_size, render_mode=\"console\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        self.agent_pos_x = random.randint(0, self.grid_size)\n",
    "        self.agent_pos_y = random.randint(0, self.grid_size)\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=self.grid_size, shape=(2,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        match action:\n",
    "            case GridWorld.LEFT:\n",
    "                self.agent_pos_x -= 1\n",
    "            case GridWorld.RIGHT:\n",
    "                self.agent_pos_x += 1\n",
    "            case GridWorld.UP:\n",
    "                self.agent_pos_y += 1\n",
    "            case GridWorld.DOWN:\n",
    "                self.agent_pos_y -= 1\n",
    "            \n",
    "        self.agent_pos_x = np.clip(0, self.agent_pos_x, self.grid_size)\n",
    "        self.agent_pos_y = np.clip(0, self.agent_pos_y, self.grid_size)\n",
    "\n",
    "        observation = np.array([self.agent_pos_x, self.agent_pos_y]).astype(np.float32)\n",
    "        info = {}\n",
    "\n",
    "        terminated = bool(self.agent_pos_x == 0 and self.agent_pos_y == 0)\n",
    "        truncated = False\n",
    "\n",
    "        reward = 1 if terminated else 0\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \n",
    "        super().reset(seed=seed, options=options)\n",
    "\n",
    "        random.seed = seed\n",
    "        self.agent_pos_x = random.randint(0, self.grid_size)\n",
    "        self.agent_pos_y = random.randint(0, self.grid_size)\n",
    "\n",
    "        observation = np.array([self.agent_pos_x, self.agent_pos_y]).astype(np.float32)\n",
    "        info = {}\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if self.agent_pos_x == i and self.agent_pos_y == j:\n",
    "                    print(\"x\", end=\"\")\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "            print(\"\")\n",
    "    \n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Discrete(4)\n",
      "Box(0.0, 5.0, (2,), float32)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "env.render()\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 0\n",
      ".....\n",
      "...x.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Step 2: 0\n",
      "...x.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Step 3: 3\n",
      "..x..\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Step 4: 3\n",
      ".x...\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Step 5: 3\n",
      "x....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Finished at step 5 with reward 1\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "obs, _ = env.reset()\n",
    "\n",
    "step = 1\n",
    "\n",
    "while not done:\n",
    "    if obs[0] > 0:\n",
    "        action = GridWorld.LEFT\n",
    "    else:\n",
    "        action = GridWorld.DOWN\n",
    "    \n",
    "    print(f\"Step {step}: {action}\")\n",
    "\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        print(f\"Finished at step {step} with reward {reward}\")\n",
    "\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(GridWorld, n_envs=1, env_kwargs=dict(grid_size=10, render_mode=\"console\"))\n",
    "env = GridWorld(grid_size=10, render_mode=\"console\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 52.1     |\n",
      "|    ep_rew_mean        | 1        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2034     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | -43.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 25.4     |\n",
      "|    ep_rew_mean        | 1        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2339     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.853   |\n",
      "|    explained_variance | -2.93    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0334  |\n",
      "|    value_loss         | 0.0039   |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", env, verbose=1).learn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".x........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Step: 7, Obs: [[9. 6.]], Action: (array([3]), None), Reward: [1.]\n",
      "Finished at step 7 with reward [1.]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "obs = vec_env.reset()\n",
    "done = False\n",
    "step = 1\n",
    "\n",
    "while not done:\n",
    "    clear_output(wait=True)\n",
    "    vec_env.render()\n",
    "    sleep(.1)\n",
    "\n",
    "    action = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _ = vec_env.step(action)\n",
    "    \n",
    "    print(f\"Step: {step}, Obs: {obs}, Action: {action}, Reward: {reward}\")\n",
    "\n",
    "    if done:\n",
    "        print(f\"Finished at step {step} with reward {reward}\")\n",
    "\n",
    "    step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
